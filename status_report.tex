\documentclass[fleqn]{article}

%% Language and font encodings
\renewcommand{\familydefault}{\sfdefault} % use sans serif per default
\usepackage{helvet} % use helvetica per default

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=1.5cm,bottom=1.5cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath,amssymb} % for advanced math formulas
\setlength{\mathindent}{0pt}
\usepackage{hyperref}
\usepackage{graphicx}

\title{Status report - Siamese networks for instance retrieval}
\author{Matthias Kohl}

\begin{document}
\maketitle

This report serves as a status report for the internship on
siamese networks for instance retrieval,
supervised by Georges QuÃ©not and Jean-Pierre Chevallet,
in collaboration with Maxime Portaz.

This report should not be seen as a scientific report.
Instead, it is a simple overview of the main ideas and
results of the internship so far and will be updated on the fly.

\section{Introduction}
We consider the problem of instance search for images.
The goal is as follows:
given a reference dataset of images and a query image,
retrieve the image from the reference dataset that
best suits the query image.

This problem is related to image classification:
if we consider each instance of an object as a class,
we can classify the query image and return any image
from that class in the reference dataset.

The difference with image classification is that
there is almost no variability within the classes,
as they are in fact a single object.
So the objective is to focus more on differentiating between objects,
rather than predicting the type of object.
Thus for a given query image, we try to tell how much it ressembles each
image of the reference dataset.

\section{State of the art}
Previously, most systems were based on a bag-of-words approach
in order to match images~\cite{philbin_object_2007}.
Combined with better techniques of matching the bag-of-words descriptors,
this approach was previously the state-of-the-art~\cite{mikulik_learning_2013}.

Recently, the state-of-the-art has drastically improved due to the
addition of learned features, based on convolutional neural networks
(CNNs).
This new approach greatly improved
mean average precision scores~\cite{gordo_deep_2016} of the system
on the same datasets.

The general trend is to move from an approach based on a combination of
engineered features (bag-of-words combined with
support vector machines or SVMs) to a more end-to-end learning of
the matching of two images.

For this, the siamese architecture is used, where the convolutional
features of two or more CNNs with shared weights are combined and a
multi-way loss is optimized, which discriminates between the features
of two or more images.
This concept was first introduced by
Chopra et al~\cite{chopra_learning_2005} to learn a dissimilarity metric
between two images.

It was then extended to a triplet loss by
Weinberger et al~\cite{weinberger_distance_2006}, which allows for
more stable convergence.

Using this triplet loss has achieved state-of-the-art results in both
face recognition~\cite{schroff_facenet:_2015} and
image retrieval~\cite{gordo_deep_2016}. This is mostly due to the usage
of far deeper CNNs, moving from architectures such as
AlexNet~\cite{krizhevsky_imagenet_2012} to VGG~\cite{simonyan_very_2014}
and finally Inception~\cite{szegedy_inception-v4_2016} and
ResNet~\cite{he_deep_2015}.

The higher depth of networks like ResNet and Inception as compared to
AlexNet allows for higher regularization and thus less overfitting
to a specific dataset for these architectures. Batch normalization
increases this effect even more. This is a desirable trait for image
retrieval, as the variability within each instance is too small to
learn classification directly. So the better we can generalize
features learned from a bigger dataset to the reference dataset,
the better performance we can expect.

\section{Evaluation}
We are using the following datasets in our experiments:
\begin{enumerate}
    \item CLICIDE: dataset of photographs taken in an art museum,
    consisting exclusively of paintings. The dataset is characteristic
    because the different images for each instance consist of one
    global view of the instance and multiple sub-parts.

    Number of reference images: 3245
    Number of test images: 177
    Number of instances: 464
    \item GaRoFou_I: dataset of photographs of an art museum,
    consisting of display cabinets, which contain sculptures,
    rocks and various types of objects.

    Number of reference images: 1068
    Number of test images: 184
    Number of instances: 311
    % \item GaRoFou_V: dataset of frames from a video taken by visitors
    % of the same museum as above.

    % Number of reference images: 2779
    % Number of test images: 2132
    % Number of instances: 215
    % \item Oxford5k: dataset of photographs of buildings taken in
    % the city of Oxford, UK.

    % Number of reference images: 5000 TODO
    % Number of test images: 55 TODO
    % Number of instances: 17 TODO
\end{enumerate}

\subsection{Evaluation metrics}
As of now, we use the top-1 precision to evaluate the system.

We plan on using the MAP score as well in the future.

\section{Methodology}

The following approaches have been tested:
TODO
Different approaches (nets + only classif or more...)
Data augmentation ?
Triplet selection ?

\section{Results}
Current results for each approach


\newpage
\appendix
\section{Implementation details and specifics}
PyTorch
specific issues: large images/large batch sizes/large nets -> lots of memory

\bibliographystyle{ieeetr}
\bibliography{siamese}

\end{document}
